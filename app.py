#!/usr/bin/env python3
"""
Servicio CrewAI - An√°lisis Modular
Se enfoca √öNICAMENTE en el an√°lisis de documentos usando CrewAI.
Recibe llamadas HTTP directas del servicio de ingesti√≥n de documentos.
MANTIENE LA MODULARIDAD: Solo an√°lisis, sin dependencias externas.
"""

import os
import asyncio
import httpx
import logging
from typing import List, Optional, Dict, Any
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
from dotenv import load_dotenv
from datetime import datetime
from pathlib import Path
import json
from supabase import create_client, Client

# Cargar variables de entorno
load_dotenv()

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Variables de entorno para Supabase
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.getenv("SUPABASE_SERVICE_KEY")

# Configuraci√≥n del servicio
SERVICE_NAME = "CrewAI Analysis Service - Modular"
SERVICE_PORT = int(os.getenv("CREWAI_SERVICE_PORT", "8002"))

# Directorio para guardar resultados
RESULTS_DIR = Path("analysis_results")
LOGS_DIR = Path("logs")

# Crear directorios si no existen
RESULTS_DIR.mkdir(parents=True, exist_ok=True)
LOGS_DIR.mkdir(parents=True, exist_ok=True)

# Inicializar cliente Supabase
supabase: Optional[Client] = None
if SUPABASE_URL and SUPABASE_SERVICE_KEY:
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)
        logger.info("‚úÖ Cliente Supabase inicializado correctamente")
    except Exception as e:
        logger.error(f"‚ùå Error al inicializar cliente Supabase: {e}")
        supabase = None
else:
    logger.warning("‚ö†Ô∏è Variables de Supabase no configuradas")

# Verificar si CrewAI est√° disponible
CREWAI_AVAILABLE = False
try:
    from cadastro_crew.crew import CadastroCrew
    CREWAI_AVAILABLE = True
    logger.info("‚úÖ CrewAI disponible - an√°lisis real habilitado")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è CrewAI no disponible - modo simulaci√≥n: {e}")

app = FastAPI(
    title=SERVICE_NAME,
    description="Servicio modular de an√°lisis CrewAI - Solo an√°lisis, sin dependencias externas"
)

# Modelos Pydantic
class CrewAIAnalysisRequest(BaseModel):
    case_id: str
    documents: List[Dict[str, Any]]
    checklist_url: str
    current_date: str
    pipe_id: Optional[str] = None

class AnalysisResult(BaseModel):
    case_id: str
    pipe_id: Optional[str] = None
    status: str
    message: str
    risk_score: Optional[str] = None  # "Alto", "Medio", "Baixo"
    risk_score_numeric: Optional[int] = None  # 0-100
    full_analysis_report: Optional[str] = None  # Informe completo en markdown
    summary_report: Optional[str] = None  # Resumen para sistemas externos
    timestamp: str
    documents_analyzed: int
    crewai_available: bool
    analysis_details: Optional[Dict[str, Any]] = None

async def download_checklist_content(checklist_url: str) -> str:
    """Descarga el contenido del checklist desde la URL."""
    try:
        logger.info(f"üì• Descargando checklist desde: {checklist_url}")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(checklist_url)
            response.raise_for_status()
            
            # Si es un PDF, extraer texto (simplificado para este ejemplo)
            if checklist_url.lower().endswith('.pdf'):
                logger.info("üìÑ Archivo PDF detectado - usando contenido simulado...")
                return """
CHECKLIST DE CADASTRO PESSOA JUR√çDICA

1. DOCUMENTOS OBRIGAT√ìRIOS:
   - Contrato Social atualizado
   - Comprovante de resid√™ncia da empresa
   - Documento de identidade dos s√≥cios
   - Declara√ß√£o de impostos (√∫ltimo ano)
   - Certificado de registro na junta comercial

2. CRIT√âRIOS DE VALIDA√á√ÉO:
   - Documentos devem estar leg√≠veis
   - Datas n√£o podem estar vencidas
   - Assinaturas devem estar presentes
   - Informa√ß√µes devem ser consistentes entre documentos
                """
            else:
                content = response.text
                logger.info(f"üìÑ Contenido del checklist descargado: {len(content)} caracteres")
                return content
                
    except Exception as e:
        logger.error(f"‚ùå Error al descargar checklist: {e}")
        return f"Error al descargar checklist desde {checklist_url}: {e}"

async def analyze_documents_with_crewai(request: CrewAIAnalysisRequest) -> AnalysisResult:
    """Analiza documentos usando CrewAI."""
    # Inicializar variables para evitar problemas de scope
    crew_inputs = None
    checklist_content = ""
    
    try:
        logger.info(f"üîç Iniciando an√°lisis CrewAI para case_id: {request.case_id}")
        logger.info(f"üìÑ Documentos a analizar: {len(request.documents)}")
        logger.info(f"üìã Checklist URL: {request.checklist_url}")
        
        if not CREWAI_AVAILABLE:
            logger.warning("‚ö†Ô∏è CrewAI no disponible - ejecutando an√°lisis simulado")
            
            # An√°lisis simulado detallado
            simulated_analysis = {
                "compliance_score": 85.5,
                "missing_documents": ["comprovante_residencia", "declaracao_impostos"],
                "document_analysis": [
                    {
                        "document": doc["name"],
                        "tag": doc["document_tag"],
                        "status": "compliant" if "contrato" in doc["name"].lower() else "needs_review",
                        "confidence": 0.92
                    }
                    for doc in request.documents
                ],
                "recommendations": [
                    "Solicitar comprovante de resid√™ncia atualizado",
                    "Verificar declara√ß√£o de impostos do √∫ltimo a√±o",
                    "Confirmar assinatura digital nos contratos"
                ]
            }
            
            simulated_result = AnalysisResult(
                case_id=request.case_id,
                pipe_id=request.pipe_id,
                status="simulated_success",
                message=f"An√°lisis simulado completado para {len(request.documents)} documentos",
                risk_score="M√©dio",
                risk_score_numeric=60,
                full_analysis_report="An√°lisis simulado - CrewAI no disponible. Score de Risco: M√©dio. Documentos analizados correctamente.",
                summary_report=f"Score de Risco: M√©dio | An√°lisis simulado completado para {len(request.documents)} documentos | Verificar documentos faltantes",
                timestamp=datetime.now().isoformat(),
                documents_analyzed=len(request.documents),
                crewai_available=False,
                analysis_details=simulated_analysis
            )
            
            # üíæ GUARDAR RESULTADOS SIMULADOS EN ARCHIVOS
            logger.info(f"üíæ Guardando resultados del an√°lisis simulado...")
            
            # Guardar en Markdown
            markdown_path = await save_analysis_result_to_markdown(simulated_result)
            if markdown_path:
                logger.info(f"üìÑ Resultado Simulado Markdown: {markdown_path}")
            
            # Guardar en JSON
            json_path = await save_analysis_result_to_json(simulated_result)
            if json_path:
                logger.info(f"üìÑ Resultado Simulado JSON: {json_path}")
            
            # Guardar en Supabase
            await save_analysis_result_to_supabase(simulated_result)
            
            return simulated_result
        
        # Descargar contenido del checklist
        logger.info("üì• Descargando contenido del checklist...")
        checklist_content = await download_checklist_content(request.checklist_url)
        
        # Preparar inputs para la crew
        crew_inputs = {
            "case_id": request.case_id,
            "checklist": checklist_content,  # Contenido del checklist, no URL
            "current_date": request.current_date,
            "documents": request.documents
        }
        
        logger.info(f"üöÄ Ejecutando CrewAI con {len(request.documents)} documentos...")
        
        # Crear instancia de la crew
        crew = CadastroCrew(inputs=crew_inputs)
        
        # Ejecutar la crew
        result = crew.run()
        
        logger.info(f"‚úÖ An√°lisis CrewAI completado para case_id: {request.case_id}")
        
        # Procesar resultado de CrewAI
        crew_result_str = str(result)
        
        # Extraer score de riesgo del resultado
        risk_score, risk_score_numeric = await extract_risk_score_from_analysis(crew_result_str)
        
        # Generar resumen para sistemas externos
        summary_report = await generate_summary_report(crew_result_str, risk_score)
        
        analysis_details = {
            "crew_result": crew_result_str,
            "execution_time": datetime.now().isoformat(),
            "documents_processed": len(request.documents),
            "checklist_used": request.checklist_url
        }
        
        analysis_result = AnalysisResult(
            case_id=request.case_id,
            pipe_id=request.pipe_id,
            status="success",
            message=f"An√°lisis CrewAI completado exitosamente para {len(request.documents)} documentos",
            risk_score=risk_score,
            risk_score_numeric=risk_score_numeric,
            full_analysis_report=crew_result_str,
            summary_report=summary_report,
            timestamp=datetime.now().isoformat(),
            documents_analyzed=len(request.documents),
            crewai_available=True,
            analysis_details=analysis_details
        )
        
        # üíæ GUARDAR RESULTADOS EN ARCHIVOS
        logger.info(f"üíæ Guardando resultados del an√°lisis...")
        
        # Guardar en Markdown
        markdown_path = await save_analysis_result_to_markdown(analysis_result)
        if markdown_path:
            logger.info(f"üìÑ Resultado Markdown: {markdown_path}")
        
        # Guardar en JSON
        json_path = await save_analysis_result_to_json(analysis_result)
        if json_path:
            logger.info(f"üìÑ Resultado JSON: {json_path}")
        
        # Guardar en Supabase
        await save_analysis_result_to_supabase(analysis_result)
        
        return analysis_result
        
    except Exception as e:
        logger.error(f"‚ùå Error en an√°lisis CrewAI para case_id {request.case_id}: {e}")
        
        # Informaci√≥n adicional para debugging
        error_details = {
            "error": str(e),
            "error_type": type(e).__name__,
            "crew_inputs_defined": crew_inputs is not None,
            "checklist_content_length": len(checklist_content) if checklist_content else 0
        }
        
        return AnalysisResult(
            case_id=request.case_id,
            pipe_id=request.pipe_id,
            status="error",
            message=f"Error en an√°lisis CrewAI: {str(e)}",
            risk_score="Alto",  # Error = riesgo alto
            risk_score_numeric=90,
            full_analysis_report=f"Error en an√°lisis: {str(e)}",
            summary_report=f"Score de Risco: Alto | Error en an√°lisis: {str(e)[:100]}...",
            timestamp=datetime.now().isoformat(),
            documents_analyzed=0,
            crewai_available=CREWAI_AVAILABLE,
            analysis_details=error_details
        )

# üîó ENDPOINT PRINCIPAL PARA COMUNICACI√ìN HTTP DIRECTA
@app.post("/analyze")
async def analyze_documents_endpoint(request: CrewAIAnalysisRequest, background_tasks: BackgroundTasks):
    """
    Endpoint principal para an√°lisis de documentos.
    Recibe llamadas HTTP directas del servicio de ingesti√≥n.
    MANTIENE LA MODULARIDAD: Se enfoca solo en an√°lisis CrewAI.
    """
    try:
        logger.info(f"üîó Solicitud de an√°lisis HTTP directa recibida para case_id: {request.case_id}")
        logger.info(f"üìÑ Documentos a analizar: {len(request.documents)}")
        logger.info(f"üîó Pipe ID: {request.pipe_id}")
        
        # Procesar an√°lisis en background para respuesta r√°pida
        background_tasks.add_task(analyze_documents_with_crewai, request)
        
        return {
            "status": "accepted",
            "message": f"An√°lisis iniciado para case_id: {request.case_id}",
            "case_id": request.case_id,
            "documents_count": len(request.documents),
            "processing": "background",
            "service": "crewai_analysis_service",
            "communication": "http_direct",
            "crewai_available": CREWAI_AVAILABLE
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error al procesar solicitud de an√°lisis: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze/sync")
async def analyze_documents_sync(request: CrewAIAnalysisRequest):
    """
    Endpoint s√≠ncrono para an√°lisis de documentos.
    Espera a que el an√°lisis termine antes de responder.
    """
    try:
        logger.info(f"üîó Solicitud de an√°lisis S√çNCRONA recibida para case_id: {request.case_id}")
        
        # Ejecutar an√°lisis de forma s√≠ncrona
        result = await analyze_documents_with_crewai(request)
        
        return {
            "status": "completed",
            "analysis_result": result.model_dump(),
            "service": "crewai_analysis_service",
            "communication": "http_direct_sync",
            "crewai_available": CREWAI_AVAILABLE
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error en an√°lisis s√≠ncrono: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """Endpoint de salud."""
    return {
        "status": "healthy",
        "service": "crewai_analysis_service",
        "crewai_available": CREWAI_AVAILABLE,
        "architecture": "modular",
        "communication": "http_direct",
        "endpoints": {
            "async_analysis": "POST /analyze",
            "sync_analysis": "POST /analyze/sync",
            "health": "GET /health"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/")
async def root():
    return {
        "service": "CrewAI Analysis Service - Modular",
        "description": "Servicio modular de an√°lisis CrewAI - Solo an√°lisis, sin dependencias externas",
        "architecture": "modular",
        "communication": "http_direct",
        "crewai_available": CREWAI_AVAILABLE,
        "version": "modular_v2.0",
        "endpoints": {
            "async_analysis": "POST /analyze - An√°lisis en background",
            "sync_analysis": "POST /analyze/sync - An√°lisis s√≠ncrono",
            "health": "GET /health - Estado del servicio",
            "root": "GET / - Informaci√≥n del servicio"
        }
    }

@app.get("/status")
async def service_status():
    """Estado detallado del servicio."""
    return {
        "service": SERVICE_NAME,
        "status": "running",
        "port": SERVICE_PORT,
        "crewai_available": CREWAI_AVAILABLE,
        "supabase_connected": supabase is not None,
        "communication": "http_direct",
        "architecture": "modular",
        "timestamp": datetime.now().isoformat(),
        "integrations": {
            "supabase": {
                "connected": supabase is not None,
                "url": SUPABASE_URL[:50] + "..." if SUPABASE_URL else None
            }
        },
        "endpoints": {
            "analyze": "/analyze (POST) - An√°lisis as√≠ncrono",
            "analyze_sync": "/analyze/sync (POST) - An√°lisis s√≠ncrono", 
            "health": "/health (GET) - Health check",
            "status": "/status (GET) - Estado del servicio",
            "informes": "/informes (GET) - Consultar informes guardados",
            "informe": "/informe/{case_id} (GET) - Consultar informe espec√≠fico"
        }
    }

@app.get("/informes")
async def get_all_informes():
    """Consulta todos los informes guardados en la tabla informe_cadastro."""
    try:
        if not supabase:
            raise HTTPException(status_code=500, detail="Cliente Supabase no disponible")
        
        response = supabase.table("informe_cadastro").select("*").order("created_at", desc=True).execute()
        
        return {
            "status": "success",
            "count": len(response.data),
            "informes": response.data
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error al consultar informes: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/informe/{case_id}")
async def get_informe_by_case_id(case_id: str):
    """Consulta el informe espec√≠fico de un case_id."""
    try:
        if not supabase:
            raise HTTPException(status_code=500, detail="Cliente Supabase no disponible")
        
        response = supabase.table("informe_cadastro").select("*").eq("case_id", case_id).order("created_at", desc=True).execute()
        
        if not response.data:
            raise HTTPException(status_code=404, detail=f"No se encontr√≥ informe para case_id: {case_id}")
        
        return {
            "status": "success",
            "case_id": case_id,
            "informe": response.data[0]  # M√°s reciente
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error al consultar informe para case_id {case_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def save_analysis_result_to_markdown(result: "AnalysisResult") -> str:
    """Guarda el resultado del an√°lisis en un archivo Markdown."""
    try:
        # Crear nombre de archivo con timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"analysis_{result.case_id}_{timestamp}.md"
        filepath = RESULTS_DIR / filename
        
        # Crear contenido Markdown
        markdown_content = f"""# üìä An√°lisis CrewAI - Case ID: {result.case_id}

## üìã Informaci√≥n General
- **Case ID**: {result.case_id}
- **Estado**: {result.status}
- **Timestamp**: {result.timestamp}
- **Documentos Analizados**: {result.documents_analyzed}
- **CrewAI Disponible**: {'‚úÖ S√≠' if result.crewai_available else '‚ùå No (Simulado)'}

## üìÑ Mensaje del An√°lisis
{result.message}

## üîç Detalles del An√°lisis
"""
        
        if result.analysis_details:
            # Si es an√°lisis real de CrewAI
            if result.crewai_available and "crew_result" in result.analysis_details:
                markdown_content += f"""
### ü§ñ Resultado de CrewAI
```
{result.analysis_details.get('crew_result', 'No disponible')}
```

### ‚è±Ô∏è Informaci√≥n de Ejecuci√≥n
- **Tiempo de Ejecuci√≥n**: {result.analysis_details.get('execution_time', 'No disponible')}
- **Documentos Procesados**: {result.analysis_details.get('documents_processed', 0)}
- **Checklist Utilizado**: {result.analysis_details.get('checklist_used', 'No disponible')}
"""
            
            # Si es an√°lisis simulado
            elif not result.crewai_available and isinstance(result.analysis_details, dict):
                details = result.analysis_details
                markdown_content += f"""
### üìä An√°lisis Simulado
- **Score de Cumplimiento**: {details.get('compliance_score', 'N/A')}%

#### üìã Documentos Faltantes
"""
                for doc in details.get('missing_documents', []):
                    markdown_content += f"- {doc}\n"
                
                markdown_content += "\n#### üìÑ An√°lisis de Documentos\n"
                for doc_analysis in details.get('document_analysis', []):
                    status_emoji = "‚úÖ" if doc_analysis.get('status') == 'compliant' else "‚ö†Ô∏è"
                    markdown_content += f"""
- **{doc_analysis.get('document', 'N/A')}**
  - Tag: {doc_analysis.get('tag', 'N/A')}
  - Estado: {status_emoji} {doc_analysis.get('status', 'N/A')}
  - Confianza: {doc_analysis.get('confidence', 0):.2%}
"""
                
                markdown_content += "\n#### üí° Recomendaciones\n"
                for rec in details.get('recommendations', []):
                    markdown_content += f"- {rec}\n"
            
            # Si hay error
            elif "error" in result.analysis_details:
                markdown_content += f"""
### ‚ùå Error en el An√°lisis
```
{result.analysis_details.get('error', 'Error desconocido')}
```
"""
        
        markdown_content += f"""

---
*An√°lisis generado por {SERVICE_NAME} el {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # Guardar archivo
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        logger.info(f"üíæ Resultado guardado en: {filepath}")
        return str(filepath)
        
    except Exception as e:
        logger.error(f"‚ùå Error al guardar resultado en Markdown: {e}")
        return ""

async def save_analysis_result_to_json(result: "AnalysisResult") -> str:
    """Guarda el resultado del an√°lisis en un archivo JSON para futura migraci√≥n a Supabase."""
    try:
        # Crear nombre de archivo con timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"analysis_{result.case_id}_{timestamp}.json"
        filepath = RESULTS_DIR / filename
        
        # Preparar datos para JSON (estructura compatible con futura tabla Supabase)
        json_data = {
            "case_id": result.case_id,
            "status": result.status,
            "message": result.message,
            "timestamp": result.timestamp,
            "documents_analyzed": result.documents_analyzed,
            "crewai_available": result.crewai_available,
            "analysis_details": result.analysis_details,
            "created_at": datetime.now().isoformat(),
            "service_version": "modular_v2.0",
            "architecture": "modular"
        }
        
        # Guardar archivo JSON
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üíæ Resultado JSON guardado en: {filepath}")
        return str(filepath)
        
    except Exception as e:
        logger.error(f"‚ùå Error al guardar resultado en JSON: {e}")
        return ""

async def save_analysis_result_to_supabase(result: "AnalysisResult") -> bool:
    """
    Guarda el resultado del an√°lisis en la tabla informe_cadastro de Supabase.
    MODULAR: Solo guarda en Supabase, no actualiza sistemas externos.
    
    Estructura de tabla 'informe_cadastro':
    - id (uuid, primary key)
    - case_id (text) - ID del caso/cliente que coincide con case_id de la tabla documents
    - informe (text) - Informe completo generado por la crew en formato markdown
    - risk_score (text) - Score de riesgo categ√≥rico (Bajo, Medio, Alto)
    - risk_score_numeric (integer) - Score de riesgo num√©rico (0-100)
    - summary_report (text) - Resumen del informe para sistemas externos
    - documents_analyzed (integer) - N√∫mero de documentos analizados
    - crewai_available (boolean) - Si CrewAI estaba disponible
    - analysis_details (jsonb) - Detalles adicionales del an√°lisis en formato JSON
    - status (text) - Estado del an√°lisis
    - created_at (timestamptz) - Fecha de creaci√≥n
    - updated_at (timestamptz) - Fecha de √∫ltima actualizaci√≥n
    """
    try:
        if not supabase:
            logger.error("‚ùå Cliente Supabase no est√° disponible")
            return False
        
        # Preparar datos para insertar en la tabla informe_cadastro
        data = {
            "case_id": result.case_id,
            "informe": result.full_analysis_report or result.message,
            "risk_score": result.risk_score,
            "risk_score_numeric": result.risk_score_numeric,
            "summary_report": result.summary_report,
            "documents_analyzed": result.documents_analyzed,
            "crewai_available": result.crewai_available,
            "analysis_details": result.analysis_details,
            "status": result.status
        }
        
        # Insertar en Supabase
        response = supabase.table("informe_cadastro").insert(data).execute()
        
        if response.data:
            logger.info(f"‚úÖ Informe guardado en Supabase - case_id: {result.case_id}, id: {response.data[0].get('id')}")
            logger.info(f"üîî Webhook de Supabase se activar√° autom√°ticamente para actualizar sistemas externos")
            return True
        else:
            logger.error(f"‚ùå Error al guardar informe en Supabase - No se recibieron datos")
            return False
        
    except Exception as e:
        logger.error(f"‚ùå Error al guardar informe en Supabase: {e}")
        return False

async def extract_risk_score_from_analysis(crew_result: str) -> tuple[str, int]:
    """
    Extrae el score de riesgo del resultado de CrewAI.
    Busca patrones como "Score de Risco: Alto" o "Risco: M√©dio" etc.
    
    Returns:
        tuple: (risk_score_text, risk_score_numeric)
    """
    try:
        if not crew_result:
            return "M√©dio", 50
        
        # Convertir a min√∫sculas para b√∫squeda
        result_lower = crew_result.lower()
        
        # Patrones de b√∫squeda para score de riesgo
        risk_patterns = [
            r"score de risco[:\s]*([a-z√°√™√ß√µ]+)",
            r"risco[:\s]*([a-z√°√™√ß√µ]+)",
            r"classifica√ß√£o[:\s]*([a-z√°√™√ß√µ]+)",
            r"n√≠vel de risco[:\s]*([a-z√°√™√ß√µ]+)"
        ]
        
        import re
        
        for pattern in risk_patterns:
            match = re.search(pattern, result_lower)
            if match:
                risk_text = match.group(1).strip()
                
                # Mapear texto a valores num√©ricos
                if "alto" in risk_text or "high" in risk_text:
                    return "Alto", 80
                elif "m√©dio" in risk_text or "medio" in risk_text or "medium" in risk_text:
                    return "M√©dio", 50
                elif "baixo" in risk_text or "low" in risk_text:
                    return "Baixo", 20
        
        # Si no encuentra patr√≥n espec√≠fico, analizar contenido general
        if any(word in result_lower for word in ["cr√≠tico", "grave", "urgente", "alto risco"]):
            return "Alto", 75
        elif any(word in result_lower for word in ["baixo risco", "conforme", "adequado"]):
            return "Baixo", 25
        else:
            return "M√©dio", 50
            
    except Exception as e:
        logger.error(f"‚ùå Error al extraer score de riesgo: {e}")
        return "M√©dio", 50

async def generate_summary_report(crew_result: str, risk_score: str) -> str:
    """
    Genera un resumen conciso del an√°lisis para sistemas externos.
    M√°ximo 500 caracteres para compatibilidad con sistemas externos.
    """
    try:
        if not crew_result:
            return f"An√°lisis completado. Score de Risco: {risk_score}. Consulte el informe completo para m√°s detalles."
        
        # Extraer las primeras l√≠neas m√°s importantes
        lines = crew_result.split('\n')
        important_lines = []
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#') and len(line) > 10:
                # Buscar l√≠neas con informaci√≥n clave
                if any(keyword in line.lower() for keyword in [
                    'score', 'risco', 'recomenda√ß√£o', 'conclus√£o', 
                    'status', 'conformidade', 'documentos'
                ]):
                    important_lines.append(line)
                    if len(important_lines) >= 3:  # M√°ximo 3 l√≠neas importantes
                        break
        
        # Construir resumen
        if important_lines:
            summary = " | ".join(important_lines)
        else:
            # Fallback: tomar las primeras l√≠neas no vac√≠as
            summary = " ".join([line.strip() for line in lines[:3] if line.strip()])
        
        # Agregar score de riesgo al final
        summary = f"Score de Risco: {risk_score} | {summary}"
        
        # Truncar si es muy largo (m√°ximo 450 caracteres para dejar espacio)
        if len(summary) > 450:
            summary = summary[:447] + "..."
        
        return summary
        
    except Exception as e:
        logger.error(f"‚ùå Error al generar resumen: {e}")
        return f"An√°lisis completado. Score de Risco: {risk_score}. Error al generar resumen."

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=SERVICE_PORT) 